{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 13\n",
    "## Applied Machine Learning\n",
    "\n",
    "Andrew Chan \n",
    "EBE869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJg5agtD4NTU",
    "outputId": "4de5abf0-8cdc-445f-a2a7-4007ad36a9c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 1.6.0\n",
      "CUDA available= False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bux0od6D4PG4",
    "outputId": "fea7deb1-8522-402b-937b-1d5fa9f87fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type= torch.FloatTensor\n",
      "Shape/size= torch.Size([2, 3])\n",
      "Values= tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 5.9694e-39]])\n"
     ]
    }
   ],
   "source": [
    "# A helper function to display properties of the Python objects\n",
    "def describe(x):\n",
    "    print(f\"Type= {x.type()}\")\n",
    "    print(f\"Shape/size= {x.shape}\")\n",
    "    print(f\"Values= {x}\")\n",
    "\n",
    "# Random tensor, has dummy values from the computer memory - not initialized\n",
    "describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ffF8kylWsPWr"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deDoK9Yiup4Q"
   },
   "source": [
    "# 1. [20 pts] Pre-process a single file using 20 frequency bins (i.e. M), and 2000 sampling frequency (controls the number of data points)\n",
    "\n",
    "cat_1.wav file (signal) will generate 20 features, and 44 data points. Note that 2000Hz\n",
    "sampling frequency in fact would ignore frequencies higher than 1000Hz and we assume\n",
    "cats and dogs sounds are less than that range. Changing that limit to 3k, and 4k are\n",
    "suggested, but then this will increase the number of data points to be processed.\n",
    "Display the spectrogram in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7qCfIJu7xED6"
   },
   "outputs": [],
   "source": [
    "Path_dataset = './audioCatsDog/cats_dogs/'\n",
    "SAMPLING_FRQ = 2000\n",
    "M = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "6DZyej_k42r1",
    "outputId": "2cb55373-fae2-4050-acde-fd3a8bef3723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x29e5c5cb820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEGCAYAAABbzE8LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWgklEQVR4nO3de4zld1nH8c9zbnPbnZnupdst2267UMo1QEEEIUi4GBRDlVSDiYYoGrxGYqLBfxRNNEI0MUHUGKghQSBQI2IjxTUimiggl5a2QAOtbdl2293t3nfnds75+secmm33fJ9nzpydfWbg/Uqane53vr/f93x/v/PMmdl5zsdKKQIAXH6N7AUAwPcrCjAAJKEAA0ASCjAAJKEAA0CS1iifvHPbVNm/Y270szQs+IRo3PlNjb7/Wxzeb3lYY8yvP95vkFj0mDbovNG5o3Vt5G/FNJveif250XXu9apj4XUe5zqOs1/j3CMbeZ2idW3kurMe1ziPeQ1r/tpDh4+VUnY//e9HKsD7d8zp87/9c6NMkSQ1Jifc8egJUvr96lj//II/13liNiYn3bmRsrJSHbN2e6xje1+0ykrXn9rpVMes5RVBqXTr+yUFhc4tsFJj+7b6YFRgl5fc8e7pM/XzOvuxevD6/eV/0YivhXkvPiz4wuDNda6DJJVgP911Rdcx2k9Hf3nZHff2012z4nvXe05GNcrdk+BaSNLMO/7woaHnDWcCADYEBRgAklCAASAJBRgAklCAASAJBRgAklCAASAJBRgAklCAASAJBRgAkozUimztltpXXtTOPDiS03obtep5raCS1Ki3ATbnrwiOXW/JLEuL/lSnBTo69ri8tl6b2e5P9tomz59zp5Zuvb1aksxrQ/XuAUn9M6frg2to5/R0rr66Phisa5yW37HvbW+q17YbtDFHbeHePeKeV6t1wOW1QQfrspn647LoOk7P+OPetQhqgVeD1PXb0d3DrnsmAGAsFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASDJSK3Lp9tR94vjQMa89MUoujnjpxVHKr6d75qw7blFUtZPm7KUHj3tsnTzlH9u5Fha0sEbr9tp2o/bXbrBu97RRgrVz7pVjw+/ZJ42T9By1GnvpxM0oiTdIC/dE7cLjJBtHCdVu+3+Uuu2Mdc8cdef2nZRyyU9fj66Fm6g8sf695BUwACShAANAEgowACShAANAEgowACShAANAEgowACShAANAEgowACQZqRNOzYaas7NDh7zOm6iLKey+csIxw44zp5Opc801/nkjTldZWTzvTi0LQXegs+7GRNAV5hmjA0qSey3U9G+n5t5n1Ae90ENJWvGDIntHHquOtXfvdOd6XU4W7HV0HUuvHtjonVcKwlejDr3oOeWFrwbdknIe09icgMvmVXv9uVF36WL9WkVhtJ4oxNTDK2AASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAko7Ui9/rqnT0zdMgN+XNC+taieK3IK35bpNuqfOa0f+KgndMLGIxCES1qCfbaQZ1gTEnqLy7Wx06d9M8b6C/WAxlLEIrYnJmpDwbhlhFvP8dphe8df8I/sRO6KUnFeVwNp+1WkvpOaGzYvh/sp7df0b0Ztd66xw6CRr17yMZ42wFJYwXKeo85PK+3pHXPBACMhQIMAEkowACQhAIMAEkowACQhAIMAEkowACQhAIMAEkowACQhAIMAElGakW2ZlOtufnKkZxDdSb8A0dtqF4LYpTg6olaCKOU1XGOPY4gfdh21/e7tVxvJZYkBWnOY12LcfZknHskamGdqKcTN1t+crGmnfbqiJcwHQlaekNjpSIHbdBeK3OQfm0L5+qDUXJx1BbutRMH19lNqB6jjZ5XwACQhAIMAEkowACQhAIMAEkowACQhAIMAEkowACQhAIMAEkowACQhAIMAElGakUuvZ6660jV7Z9f8I8btBCak2YazfXaBJeOn/LPG7TOtrfX21Bbc07roiQbo4W6H6TS9pz9bgRpzc3t29zxKNXW461rrLZcSdaqXyv3vIHW7Kw73liqJ1BLfotrP5jrpVuHoudUcB+4c4N7oO8kG0cp5t5zPRK1ExenlbkfrMvTnJpa91xeAQNAEgowACShAANAEgowACShAANAEgowACShAANAEgowACShAANAEgowACQZLRW51VJr567hg916K18vSsMdp20yOLbXNjlx4IA7N0yHddqc+2dO+4eO0nadlsxmkMTbjo7tnje4Vl4bapAi3VjxW6jH4py7VYJ2dS9tN2j71uy8P+6sqxGkCze8eztKJl4O2pi9eztKAw9akRvefo7x1gFqO2nLkhS0drv6/n56LdQlShp38AoYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgyUityP2lJS09+ODwQae1sbltepTTXKR3+kx1rHT9FkI3LffQo+7chjM30picdMej9Fcv7dlOnPBPPkYL6zgJwlGKtLXrLdLjpOFKUn+p3jLc2bvXnVuc9tdesNf9R/17aBzNmfrzZpx0amnMxOWgRd9L7S5OYnJ4Wuf+keLEb+vUW5mj52vxnjdjXAteAQNAEgowACShAANAEgowACShAANAEgowACShAANAEgowACShAANAEgowACQZqRW5MTmpiRtuqBzJaROM0kyj1Nq+k5TqpahKfttklNYcJQR7SapeMqw03mNeOOdO7Z08VR/s+I+pMzfvjtuOSiq25N8Dkr9f0V5H1/nkE/XTBm231qw/DVq7r/TPG62rPVEfc1pjJQX3fXD/BAnBje2z/nxP9LzxRCnT3rGj/Yp4dSi4d81J9C6nT65zQbwCBoA0FGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASDJyKvJyJRXZrJ5q6yUTS34C8OqJ6y2ZJWrJdHips1Kc8ttfXKqOuSmqkprbt7nj7nmD5OJo3e6xzwVtzseOrfvYzamp+mCQihw9psb8jurYyncfced61yo67+LR4/6xnXu70fGffp3Z+j0S3ptB+nBzot6WG6UPW5A+XFa69bHoeeHcI70F/74PE5edtyWI1uVp75hf91xeAQNAEgowACShAANAEgowACShAANAEgowACShAANAEgowACShAANAkpE64azVUnvn8I4jm9len7gtCAB0uuhCQUClG0445XfCRUF9jV6940edSf/YYShnvTOnEQQu6nx9T3qnT7tTbdIJkZTUvuE51bHSDEI5PUEop3X9MMf+w/dXxyauv84/txfc6l1jSe1d9Q681WPX7+3GZHCPOMLOrWDcmx91lIVdiTt21gejLk1nXY2ge3ScDtAwUNYZL+fOrPu0vAIGgCQUYABIQgEGgCQUYABIQgEGgCQUYABIQgEGgCQUYABIQgEGgCQUYABIMlIrcul2tXJ0eCijnTxVnWdB4OJYvDZSBW2VDX9uI2jLNWf+8jE/rLG35LfWehpBKGLDCVVsOGGMkqRFv825f+RL9cHoWnjhl8E9EgW3em2op79417rnTszN+OsKWn7b2+rzo1BObz+joFsvyFbygzfDNufo2GfOruu80bn70XOm+Ovqd+vH9kJKpaDNOagjHl4BA0ASCjAAJKEAA0ASCjAAJKEAA0ASCjAAJKEAA0ASCjAAJKEAA0ASCjAAJBmpFbkxNa3OC188fHCl3ibY335FcGD/64A5x7blICHYSRdW228/LGFSb73NefKqq/1lbZv3j+2kJttikATtrTvar+UgfXjnnupYCfaz33Jau4O9dq+jpPaD36yO7X7RS/xDTzrtwgv1tlpJ0sqSPz5ZT94uQRr4OCnTjege8ZK1g72OWs7lPC9CE05SdNQiHaUie/sdpZg7z5tyfPjbM6wFr4ABIAkFGACSUIABIAkFGACSUIABIAkFGACSUIABIAkFGACSUIABIAkFGACSjNSK3F84r+V7vz50rDnjtFz2/ne0VT2Nl0gapax6c7vHT7hzG5N+e6KXTLt4+HF3bn+5u+5jd+a2u3O91u5+kHocpQ83HzlUHXOTYyU1vZTpYG50nTVdbyfufvtb7tSVE/VE7+6Cv19T+65yx5uzs+64y2sLD5KJu4t+i7T3mEuQLhxpeUnQQdJ4GSMtPOI+n4NUbuvU2+yjOuHhFTAAJKEAA0ASCjAAJKEAA0ASCjAAJKEAA0ASCjAAJKEAA0ASCjAAJKEAA0CSkVqRbXpG7Rf/wNCxfqfeYtjo+m23ilofnRTWKInXS3htHvCn9jpT/ic4yg/Ou+NLHb+duNWrt2ROH/6GO9fO15N8V/bs9897rt6iKgWJzM3gdnKSnkvLn2tBIm7fSbVdetbL/LlWb4NuL/vpwo3zfjt730ni9ZKvJWl5OkgTd3SCdU2dOFIfDNqcoxRzL2E4er56SeNhonfE2++F8/5cp9U9TGt28AoYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgyUityFpcUP++e9ZxFj/xNlKc1sjiJcdK6i7U02E7e3a7c6PNWTl6rDrWDto1Z671W4LVq7dvd48edacuHamv6/TDn3Hnzh3Y6443nQTYfpBo25xyEnGD/eoF6cT33/G16lh7yk9Unr92hzvumd3v71drdtu6jz25a1d9MEiR7p857Y4vHjteHfOeb5LUX/HfWqA54SQIO2OS1GjXn3XnH3XapyWdO1x/TJLUaNXvsbln7nPnds8tVMcWj/t77a5p3TMBAGOhAANAEgowACShAANAEgowACShAANAEgowACShAANAEgowACShAANAktFSkTsdNa+ptNC26u2e/UknUVRxUmq/WT92c8VvUW2u1Ntju9Oz/rpa/rpaZ56ojkWJt70JP3HZS4e1fc9057Yn6vu999ghd64W/XTY5Qfur441in87dZ7/wvqgc/9IUnHuAUm69uZfqI5NnX3cnds+frg+uFxvZZckzfjp1m5ibrDXmpyuj3npwZIaQVLv5IE5/9weJ2l89eDOuieDpHHncU2/9NX+aYMU89ZCvWXYgsTlCSeZfdvZk+5cSdIHbhv617wCBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASEIBBoAkFGAASDJSK/LZh4/qv371L4aO9RbqSarNKb/Ot7b5Ca+tyfoyd1x/hTu3M1NvJ+4u+emu0zv9NtOFE+eqY8tngxbpjr/1Kwv1lkzvMUnS3LX1tOdTTrqrJB1/wE9c7szUk42jdc075y59v3W7v+K33i6f/Yfq2OT1V7tzu05SrwUt0stOurDkr/vUg4+5cw99+RF33NNb8pONGy1b97HPPeTf22Wlfi2nnuEkY0vqzNWfF7ue7aRES9pz07Pc8b6TvL180k82Pn/0VHXs0Tsfded6eAUMAEkowACQhAIMAEkowACQhAIMAEkowACQhAIMAEkowACQhAIMAElG6oR7bPZ6/dkbPjp07Kr9e6rz/viWh93jzt39Of/EV9Q7YB7/5Kf8qc+5rjrWecGL3LnL37jbHZ979Y9Uxx654gXu3H0HP+COW7PeHXj4de9w5959tt75dfC//Q6pR+b8zq5nP//K6tj+fX7X2E/bx6tjp2+/3Z07/+pXuOP/ed0vVcem20GApdX35M6H/ODWpb1+B9+rbqx3UEWubJ2tjk0WP9Dztq/7XWH/9JEvVMd6Qddh87n+dd7jdB52Jv1uyccfrAek3vTDz3PnvvEV/uvJ6XY9oHei6T/mE4v1oNuDX/CfU5Kkdw4PKuUVMAAkoQADQBIKMAAkoQADQBIKMAAkoQADQBIKMAAkoQADQBIKMAAkoQADQBIrxW+lfMonm52RdN/GLeeS2yXpWPYiRrTV1rzV1iux5sthq61X2tg17y+lXJSWO9J7QUi6r5Tysku0oA1nZl/eSuuVtt6at9p6JdZ8OWy19Uo5a+ZHEACQhAIMAElGLcB/syGr2Dhbbb3S1lvzVluvxJovh622XilhzSP9IxwA4NLhRxAAkIQCDABJ1lSAzexNZnafmX3HzN690YsahZndamZHzOyeyvhrzeyUmd05+O/3LvcaI2Y2aWZfMrO7zOxeM/uD7DUNY2ZNM/uamV2UH7QV9lmSzGzezG4zs2+Z2TfN7JXZa5IkM7vxgr2708xOm9m7nvY5W2WPf9PM7hncy+/KXs8ww+qGme0ws4Nm9u3Bn1ds+EJKKe5/kpqS7pd0QFJH0l2SnhfNu1z/SXqNpJsk3VMZf62k27PXGTwGk7Rt8HFb0hclvSJ7XUPW+VuSPjpsP7fCPg/W+WFJvzj4uCNpPntNQ9bYlPSYVn95f0vtsaQXSLpH0rRW+wz+VdIN2esass6L6oak90l69+Djd0t670avYy2vgF8u6TullAdKKcuSPi7p5jXMuyxKKf8hyU+S3OTKqicTGNuD/zbVv46a2T5Jb5b0wey1rJeZzWr1ifchSSqlLJdSTqYuarjXS7q/lPJQ9kLW4bmSvlBKOV9K6Ur6vKSfTF7TRSp142atfoHW4M+f2Oh1rKUAP0PSdy/4/0ODv9tKXjn49v4zZvb87MUMM/j2/k5JRyQdLKV8MXlJT/fnkn5HkhcBu9n3+YCko5L+dvCjlA+aWT3uNs/bJH2sMrbZ9/geSa8xs51mNi3pxyRdk7ymtdpTSjksSYM/6xHgl8haCrAN+btN9eos8FWtfiv3Iknvl/Sp3OUMV0rplVJeLGmfpJebmZ9rfxmZ2Y9LOlJK+YrzaVthn1ta/bbzr0opL5F0Tqvfam4aZtaR9BZJnxwyvOn3uJTyTUnvlXRQ0h1a/ZFlN3VRm9haCvAhPfUr2D5Jj27Mci69UsrpJ7+9L6X8s6S2me1KXlbV4Fvif5f0ptyVPMWrJL3FzB7U6o+gXmdmH7nwE7bIPh+SdOiC7y5u02pB3kx+VNJXSymPP31gi+yxSikfKqXcVEp5jVa/zf929prW6HEz2ytJgz+PbPQJ11KA/0fSDWZ2/eCr89skfXpjl3XpmNlVZmaDj1+u1cf8RO6qnsrMdpvZ/ODjKUlvkPSt1EVdoJTyu6WUfaWU67R6/f+tlPKzF37OVtjnUspjkr5rZjcO/ur1kr6RuKRhfkaVHz9shT2WJDO7cvDntZLeqvqPUzabT0t6++Djt0v6x40+YfhuaKWUrpn9uqTPavVfZ28tpdy70QtbKzP7mFb/dXiXmR2S9Pta/UcslVL+WtItkn7FzLqSFiS9rQz+mXMT2Svpw2bW1OqT6hOllIt+1WuzMbNflrbUPkvSb0j6u8GLiQck/Xzyev7f4Gemb5T0zgv+bivu8d+b2U5JK5J+rZRyIntBT1epG38i6RNm9g5JD0v6qQ1fx+a8fgDwvY9OOABIQgEGgCQUYABIQgEGgCQUYABIQgHGpjRoZX3yXb8eM7NHBh+fNbO/zF4fcCnwa2jY9MzsPZLOllL+NHstwKXEK2BsKYP3xL198PF7zOzDZvYvZvagmb3VzN5nZneb2R1m1h583kvN7PNm9hUz++yT7aZANgowtrpnavVtMm+W9BFJnyulvFCrnWJvHhTh90u6pZTyUkm3SvqjrMUCFwpbkYFN7jOllBUzu1urrfJ3DP7+bknXSbpRq28SfnDwNgpNSYcT1glchAKMrW5JkkopfTNbueC9Efpavb9N0r2llE0RPQRciB9B4HvdfZJ2P5n9ZmbtTfpG5vg+RAHG97RBjNYtkt5rZndJulPSD6UuChjg19AAIAmvgAEgCQUYAJJQgAEgCQUYAJJQgAEgCQUYAJJQgAEgyf8BwY2kJsO8fasAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, fs = librosa.load(Path_dataset+'cat_1.wav', sr=SAMPLING_FRQ)\n",
    "mfccs = librosa.feature.mfcc(x, sr=fs, n_mfcc=M)\n",
    "librosa.display.specshow(mfccs, sr=fs, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc4CDRV2z1nj"
   },
   "source": [
    "# 2. [20 pts] For each wav file, you will have multiple data points, as generated by the librosa.feature.mfcc. \n",
    "\n",
    "Generate the X and y matrices for supervised learning. Apply your\n",
    "favorite classifier and comment about your results. (Hint: Expect 80-90% 10-fold CV\n",
    "accuracy, and N, M = 7634, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_2ldRzJz5lB",
    "outputId": "898c2207-c3b1-48c6-cc20-edfdb581afea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roNGT38K_T55",
    "outputId": "7db315de-f683-4517-d269-0254fc119bcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-K4kLWKepTc4",
    "outputId": "c294cf1b-e202-4a2c-e934-f96d9eef6743"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s7l3ktx80InL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = os.path.join(Path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8oTbwZS7NPF"
   },
   "source": [
    "Create X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3Mzr9sf47YS",
    "outputId": "b696206a-c22f-4096-f648-5b81ff249011"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1884\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1847\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1969\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1960\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2032\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_list = []\n",
    "y_list = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "       if file.endswith(\".wav\"):\n",
    "         x, fs = librosa.load(Path_dataset+file, sr=SAMPLING_FRQ)\n",
    "         mfccs = librosa.feature.mfcc(x, sr=fs, n_mfcc=M)\n",
    "         for i in range(mfccs.shape[1]):\n",
    "           X_list.append(mfccs[:,i])\n",
    "           if file.startswith(\"cat\"):\n",
    "             y_list.append(0)\n",
    "           elif file.startswith(\"dog\"):\n",
    "             y_list.append(1)\n",
    "    break # avoid recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hOFfCirm5Bka"
   },
   "outputs": [],
   "source": [
    " X = np.asarray(X_list)\n",
    " y = np.asarray(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD7u00mL7ajg",
    "outputId": "21131d9c-d246-47f2-d10b-cfa194d1f951"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGce1bjh-f1l",
    "outputId": "79cb9569-eeaa-409e-f282-132c73d3ba1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pM7DK2JWCE2S",
    "outputId": "03d61bd6-860a-4fc8-f489-aa1fdcedc66c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2396"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P-MsrLhCch1",
    "outputId": "47f6ad9c-e8cb-498d-af59-f6dcd5c05713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_ImrJ8__AdOR"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vBMKEfH_ARtH"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe_lr = LogisticRegression(random_state=14,\n",
    "               penalty='l1',\n",
    "               solver='liblinear',\n",
    "               max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGWFad41_3Gn",
    "outputId": "36f01d12-8b9a-43fd-9468-5e7f1ca27bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Acc: 0.804\n",
      "Fold:  2, Acc: 0.630\n",
      "Fold:  3, Acc: 0.836\n",
      "Fold:  4, Acc: 0.809\n",
      "Fold:  5, Acc: 0.873\n",
      "Fold:  6, Acc: 0.887\n",
      "Fold:  7, Acc: 0.903\n",
      "Fold:  8, Acc: 0.936\n",
      "Fold:  9, Acc: 0.769\n",
      "Fold: 10, Acc: 0.632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8078534031413614"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10).split(X, y)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "     pipe_lr.fit(X[train], y[train])\n",
    "     score = pipe_lr.score(X[test], y[test])\n",
    "     scores.append(score)\n",
    "     print('Fold: %2d, Acc: %.3f' % (k+1, score))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZSMfsa5BQPs"
   },
   "source": [
    "Comments:\n",
    "\n",
    "* 10 fold accuracy is about 81.50%\n",
    "* This is good as there are only 2 labels and random chance would be 50% accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxbtEq9_D6Ii"
   },
   "source": [
    "# 3. [50 pts] Train a simple RNN, as given in the module Jupyter notebook, by shuffling the list of the signals (the dataset has 277) and training the network sufficiently (suggested 50 times) and compare its performance to your previous evaluation in step (2.). \n",
    "\n",
    "Note that the train method in the module RNN can train a single signal. An epoch can be\n",
    "the training of all the signals where every signal entails the hidden layer to be initialized and\n",
    "gradients being reset at the training start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evwwhWpA92wL"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnlItEqb95Je",
    "outputId": "be82451c-dc6a-4e9d-aac5-7874c2802bd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1884\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1847\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1969\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1960\n",
      "  warnings.warn(\n",
      "C:\\Users\\ackch\\anaconda3\\envs\\torch\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2032\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "X_list = []\n",
    "y_list = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "  for file in files:\n",
    "    if file.endswith(\".wav\"):\n",
    "      x, fs = librosa.load(Path_dataset+file, sr=SAMPLING_FRQ)\n",
    "      mfccs = librosa.feature.mfcc(x, sr=fs, n_mfcc=M)\n",
    "      tensor = torch.zeros(mfccs.shape[1], 1, M)\n",
    "      for i in range(mfccs.shape[1]):\n",
    "        tensor[i][0] = torch.from_numpy(mfccs[:,i]) # should be of length M\n",
    "      X_list.append(tensor)\n",
    "      if file.startswith(\"cat\"):\n",
    "        y_list.append(torch.tensor([0]))\n",
    "      elif file.startswith(\"dog\"):\n",
    "        y_list.append(torch.tensor([1]))\n",
    "  break # avoid recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhtXg_vRqi3U"
   },
   "source": [
    "Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y7lrRYAdOqo",
    "outputId": "bc7e9535-c06a-4075-9687-3ac2023ba93d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGZXM2hidOyl",
    "outputId": "fcb58691-fa59-49ec-ca41-e3685b7edfb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-LCX4ovqXWn",
    "outputId": "75794c9f-582a-4db7-c596-c5728a9738a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 1, 20])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yosCciExD488"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X_list, y_list, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xCBJmmgOGXAF"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "all_categories = [0,1]\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, n_output, eta=0.0005,epochs=50,minibatch_size=50 ):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.i2h = nn.Linear(n_features + n_hidden, n_hidden)\n",
    "        self.i2o = nn.Linear(n_features + n_hidden, n_output)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.eta = eta  # learning rate\n",
    "        \n",
    "        # loss , since the last layer is nn.LogSoftmax\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "        self.epochs = epochs  # number of iterations\n",
    "        self.minibatch_size = minibatch_size  # size of training batch - 1 would not work\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.n_hidden)\n",
    "\n",
    "    def train_signal(self, sxx, y):\n",
    "        hidden = self.init_hidden()\n",
    "        self.zero_grad()\n",
    "\n",
    "        T = sxx.shape[0]\n",
    "        for i in range(T):\n",
    "            output, hidden = self.forward(sxx[i].reshape(1,self.n_features), hidden)\n",
    "        loss = self.criterion(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            p.data.add_(-self.eta, p.grad.data)\n",
    "\n",
    "        return output, loss.item()\n",
    "\n",
    "        \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "      for i in range(self.epochs):\n",
    "        for index in range(len(X_train)): # go through all training examples\n",
    "          output, loss = self.train_signal( X_train[index],y_train[index])\n",
    "\n",
    "    def predict_signal(self, sxx):\n",
    "      with torch.no_grad():\n",
    "        hidden = self.init_hidden()\n",
    "        T = sxx.shape[0]\n",
    "        for i in range(T):\n",
    "          output, hidden = self.forward(sxx[i].reshape(1,self.n_features), hidden)\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        return guess\n",
    "    def predict(self,x_arr):\n",
    "      y_pred = []\n",
    "      for sxx in x_arr:\n",
    "        y_pred.append(self.predict_signal(sxx))\n",
    "      return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "p-PJxBexVFPi"
   },
   "outputs": [],
   "source": [
    "def kfold_eval_docs(_clf, _Xdocs, _ydocs):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Need indexable data structure\n",
    "    acc = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    for train_index, test_index in kf.split(_Xdocs, _ydocs):\n",
    "      X_train = [ _Xdocs[i] for i in train_index]\n",
    "      y_train = [ _ydocs[i] for i in train_index]\n",
    "      X_test = [ _Xdocs[i] for i in test_index]\n",
    "      y_test = [ _ydocs[i] for i in test_index]\n",
    "      _clf.fit(X_train, y_train)\n",
    "      y_pred = _clf.predict(X_test)\n",
    "      acc += [accuracy_score(np.array(y_test), np.array(y_pred))]\n",
    "    return np.array(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqqdaWmyGXd_",
    "outputId": "b4704185-2356-436a-b2bc-083444e48246"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-b524bd6105d2>:53: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  p.data.add_(-self.eta, p.grad.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 10-fold CV accuracy= 0.77 Â±0.104\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "clf = RNN(20, 1, 2)\n",
    "\n",
    "# acc = kfold_eval_docs(clf, torch.tensor(X), torch.tensor(y))\n",
    "acc = kfold_eval_docs(clf, X, y)\n",
    "\n",
    "\n",
    "print(f\"PyTorch 10-fold CV accuracy= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmfPZ3L8xdO5"
   },
   "source": [
    "Comments:\n",
    "* Accuracy was worse than the Logistic Regression Model `77%` vs. `81.50%`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPT2LeOXwu0S"
   },
   "source": [
    "# 4. [10 pts] Compare and contrast the method applied in this assignment to the image classification\n",
    "\n",
    "* The image classification assignment was more simple the data preprocessing did not have to account for sequences of variable length.\n",
    "* The image classificaiton multilayer perceptron however was much more difficult to debug as we had to implement the backpropagation versus the simple `.backward()` function that PyTorch provides. \n",
    "* Recurrent neural networks are also very simple to create with layer definition only requiring a simple recursive reference to each layer for feedback. I could not imaging how to code this up from scratch like we did with the MLP in the image classification assignment!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chan-Assign13.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
